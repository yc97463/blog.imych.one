<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>2025 Fall Taica Generative AI 文字與圖像生成的原理與實務 筆記（持續更新中） | YC Photography</title><meta name=keywords content="修課紀錄"><meta name=description content="指令彙整
% Jupyter Notebook 魔術指令

%matplotlib inline 圖表直接顯示在頁面裡
%save filename.py 1-5 儲存第 1 到 5 行程式碼到 filename.py
%run filename.py 執行 filename.py
%timeit code 測量 code 執行時間

import 標準引入套件

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

! 執行系統指令

!ls 列出目錄內容
!pip install package 安裝 Python 套件
!pwd 顯示目前工作目錄

plot example
# 從標準常態分佈隨機抽樣
plt.plot(np.random.randn(100)) # 由標準常態分布隨機取 100 個數。

# 畫圖王牌指令: plt.plot
plt.plot([3,-5,7,2]) # 畫出 (0,3), (1, -5), (2,7),  (3,2) 四個點並連線
plt.plot(x, y) # 點的 x 座標 list, y 座標 list
plt.plot([0.8, 1.2, 2.1, 2.8], [2, -5, 3.2, 5])

# 點的表示法
points = [(0.8, 2), (1.2, -5), (2.1, 3.2), (2.8, 5)]
x = [0.8, 1.2, 2.1, 2.8]
y = [2, -5, 3.2, 5]
plt.plot(x, y, 'o') # 用圓圈表示點
plt.plot(x, y, 'ro') # 用紅色圓圈表示點
plt.plot(x, y, 'g^') # 用綠色三角形表示
互動模式
from ipywidgets import interact # 讀入 interact 函式，進入互動模式
def move(x=1):
  print(&#34; &#34;*x + &#34;oooo&#34;)
interact(move, n=(1,50))
視覺畫圖表"><meta name=author content="map[name:油成]"><link rel=canonical href=https://blog.imych.one/2025-fall-taica-generative-ai/><link crossorigin=anonymous href=/assets/css/stylesheet.5992f176555aa017ee8325dc1c15512693d0a46357ce3faf61d6456b618acca3.css integrity="sha256-WZLxdlVaoBfugyXcHBVRJpPQpGNXzj+vYdZFa2GKzKM=" rel="preload stylesheet" as=style><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=Noto+Sans+TC:wght@100..900&family=Space+Grotesk:wght@300..700&family=Space+Mono:ital,wght@0,400;0,700;1,400;1,700&&display=swap" rel=stylesheet><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://imych.one/assets/youu.png><link rel=icon type=image/png sizes=16x16 href=https://imych.one/assets/youu.png><link rel=icon type=image/png sizes=32x32 href=https://imych.one/assets/youu.png><link rel=apple-touch-icon href=https://imych.one/assets/youu.png><link rel=mask-icon href=https://imych.one/assets/youu.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://blog.imych.one/2025-fall-taica-generative-ai/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://blog.imych.one/2025-fall-taica-generative-ai/"><meta property="og:site_name" content="YC Photography"><meta property="og:title" content="2025 Fall Taica Generative AI 文字與圖像生成的原理與實務 筆記（持續更新中）"><meta property="og:description" content="指令彙整 % Jupyter Notebook 魔術指令 %matplotlib inline 圖表直接顯示在頁面裡 %save filename.py 1-5 儲存第 1 到 5 行程式碼到 filename.py %run filename.py 執行 filename.py %timeit code 測量 code 執行時間 import 標準引入套件 import numpy as np import pandas as pd import matplotlib.pyplot as plt ! 執行系統指令 !ls 列出目錄內容 !pip install package 安裝 Python 套件 !pwd 顯示目前工作目錄 plot example # 從標準常態分佈隨機抽樣 plt.plot(np.random.randn(100)) # 由標準常態分布隨機取 100 個數。 # 畫圖王牌指令: plt.plot plt.plot([3,-5,7,2]) # 畫出 (0,3), (1, -5), (2,7), (3,2) 四個點並連線 plt.plot(x, y) # 點的 x 座標 list, y 座標 list plt.plot([0.8, 1.2, 2.1, 2.8], [2, -5, 3.2, 5]) # 點的表示法 points = [(0.8, 2), (1.2, -5), (2.1, 3.2), (2.8, 5)] x = [0.8, 1.2, 2.1, 2.8] y = [2, -5, 3.2, 5] plt.plot(x, y, 'o') # 用圓圈表示點 plt.plot(x, y, 'ro') # 用紅色圓圈表示點 plt.plot(x, y, 'g^') # 用綠色三角形表示 互動模式 from ipywidgets import interact # 讀入 interact 函式，進入互動模式 def move(x=1): print(&#34; &#34;*x + &#34;oooo&#34;) interact(move, n=(1,50)) 視覺畫圖表"><meta property="og:locale" content="zh-TW"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2025-09-14T22:30:12+08:00"><meta property="article:modified_time" content="2025-09-14T22:30:12+08:00"><meta property="article:tag" content="修課紀錄"><meta property="og:image" content="https://blog.imych.one/images/banner.webp"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.imych.one/images/banner.webp"><meta name=twitter:title content="2025 Fall Taica Generative AI 文字與圖像生成的原理與實務 筆記（持續更新中）"><meta name=twitter:description content="指令彙整
% Jupyter Notebook 魔術指令

%matplotlib inline 圖表直接顯示在頁面裡
%save filename.py 1-5 儲存第 1 到 5 行程式碼到 filename.py
%run filename.py 執行 filename.py
%timeit code 測量 code 執行時間

import 標準引入套件

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

! 執行系統指令

!ls 列出目錄內容
!pip install package 安裝 Python 套件
!pwd 顯示目前工作目錄

plot example
# 從標準常態分佈隨機抽樣
plt.plot(np.random.randn(100)) # 由標準常態分布隨機取 100 個數。

# 畫圖王牌指令: plt.plot
plt.plot([3,-5,7,2]) # 畫出 (0,3), (1, -5), (2,7),  (3,2) 四個點並連線
plt.plot(x, y) # 點的 x 座標 list, y 座標 list
plt.plot([0.8, 1.2, 2.1, 2.8], [2, -5, 3.2, 5])

# 點的表示法
points = [(0.8, 2), (1.2, -5), (2.1, 3.2), (2.8, 5)]
x = [0.8, 1.2, 2.1, 2.8]
y = [2, -5, 3.2, 5]
plt.plot(x, y, 'o') # 用圓圈表示點
plt.plot(x, y, 'ro') # 用紅色圓圈表示點
plt.plot(x, y, 'g^') # 用綠色三角形表示
互動模式
from ipywidgets import interact # 讀入 interact 函式，進入互動模式
def move(x=1):
  print(&#34; &#34;*x + &#34;oooo&#34;)
interact(move, n=(1,50))
視覺畫圖表"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.imych.one/post/"},{"@type":"ListItem","position":2,"name":"2025 Fall Taica Generative AI 文字與圖像生成的原理與實務 筆記（持續更新中）","item":"https://blog.imych.one/2025-fall-taica-generative-ai/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"2025 Fall Taica Generative AI 文字與圖像生成的原理與實務 筆記（持續更新中）","name":"2025 Fall Taica Generative AI 文字與圖像生成的原理與實務 筆記（持續更新中）","description":"指令彙整 % Jupyter Notebook 魔術指令 %matplotlib inline 圖表直接顯示在頁面裡 %save filename.py 1-5 儲存第 1 到 5 行程式碼到 filename.py %run filename.py 執行 filename.py %timeit code 測量 code 執行時間 import 標準引入套件 import numpy as np import pandas as pd import matplotlib.pyplot as plt ! 執行系統指令 !ls 列出目錄內容 !pip install package 安裝 Python 套件 !pwd 顯示目前工作目錄 plot example # 從標準常態分佈隨機抽樣 plt.plot(np.random.randn(100)) # 由標準常態分布隨機取 100 個數。 # 畫圖王牌指令: plt.plot plt.plot([3,-5,7,2]) # 畫出 (0,3), (1, -5), (2,7), (3,2) 四個點並連線 plt.plot(x, y) # 點的 x 座標 list, y 座標 list plt.plot([0.8, 1.2, 2.1, 2.8], [2, -5, 3.2, 5]) # 點的表示法 points = [(0.8, 2), (1.2, -5), (2.1, 3.2), (2.8, 5)] x = [0.8, 1.2, 2.1, 2.8] y = [2, -5, 3.2, 5] plt.plot(x, y, \u0026#39;o\u0026#39;) # 用圓圈表示點 plt.plot(x, y, \u0026#39;ro\u0026#39;) # 用紅色圓圈表示點 plt.plot(x, y, \u0026#39;g^\u0026#39;) # 用綠色三角形表示 互動模式 from ipywidgets import interact # 讀入 interact 函式，進入互動模式 def move(x=1): print(\u0026#34; \u0026#34;*x + \u0026#34;oooo\u0026#34;) interact(move, n=(1,50)) 視覺畫圖表\n","keywords":["修課紀錄"],"articleBody":"指令彙整 % Jupyter Notebook 魔術指令 %matplotlib inline 圖表直接顯示在頁面裡 %save filename.py 1-5 儲存第 1 到 5 行程式碼到 filename.py %run filename.py 執行 filename.py %timeit code 測量 code 執行時間 import 標準引入套件 import numpy as np import pandas as pd import matplotlib.pyplot as plt ! 執行系統指令 !ls 列出目錄內容 !pip install package 安裝 Python 套件 !pwd 顯示目前工作目錄 plot example # 從標準常態分佈隨機抽樣 plt.plot(np.random.randn(100)) # 由標準常態分布隨機取 100 個數。 # 畫圖王牌指令: plt.plot plt.plot([3,-5,7,2]) # 畫出 (0,3), (1, -5), (2,7), (3,2) 四個點並連線 plt.plot(x, y) # 點的 x 座標 list, y 座標 list plt.plot([0.8, 1.2, 2.1, 2.8], [2, -5, 3.2, 5]) # 點的表示法 points = [(0.8, 2), (1.2, -5), (2.1, 3.2), (2.8, 5)] x = [0.8, 1.2, 2.1, 2.8] y = [2, -5, 3.2, 5] plt.plot(x, y, 'o') # 用圓圈表示點 plt.plot(x, y, 'ro') # 用紅色圓圈表示點 plt.plot(x, y, 'g^') # 用綠色三角形表示 互動模式 from ipywidgets import interact # 讀入 interact 函式，進入互動模式 def move(x=1): print(\" \"*x + \"oooo\") interact(move, n=(1,50)) 視覺畫圖表\nx = np.linspace(-5, 5, 1000) def draw(n=1): y = np.sinc(n*x) plt.plot(x,y, lw=3) 神經網路 softmax 目標是把任意的 a, b, c 三個數字, 轉化為 p1, p2, p3, 而且保持大小關係不變，而且所有數字加起來等於 1。\np1 + p2 + p3 = 1 接著，很自然地會想到用指數函數來做轉換，因為指數函數是單調遞增的函數。\nLet S = e^a + e^b + e^c Then we can define: a b c -\u003e e^a e^b e^c -\u003e e^a/S e^b/S e^c/S 每個數字經過指數函數轉換，再來按比例計算，這就是 softmax 的定義。 神經元 「神經元」是「神經網路」的基本運算單位，建立一個個隱藏層（hidden layer），每個隱藏層包含多個神經元。每個神經元會接收來自前一層的輸入，進行加權和（weighted sum）運算，然後藉由一個非線性活化函數（或稱作激發函數）（activation function）來產生輸出。\nDNN: Deep Neural Network 深度神經網路 標準全連結，全面考慮型 CNN: Convolutional Neural Network 卷積神經網路 圖形辨識能力很強 RNN: Recurrent Neural Network 循環神經網路 適合處理序列資料 有記憶的結構 Transformer: 變壓器架構 目前最流行的架構 流程：計算總刺激 -\u003e 加上偏值 -\u003e 活化函數轉換\n計算總刺激 這很像是線性迴歸的計算方式，假設有 n 個輸入 x1, x2, …, xn，對應的權重為 w1, w2, …, wn，則總刺激 z 的計算公式如下：\nz = w1*x1 + w2*x2 + ... + wn*xn 加上偏值 在計算總刺激後，會加上一個偏值（bias） b，這個偏值可以幫助模型更靈活地調整輸出。加上偏值後的公式變為：\nz = (sigma(wi*xi) from i=1 to n) + b 活化函數（激發函數）轉換 最後，將總刺激 z 放入一個非線性活化函數 fi φ 來產生神經元的輸出 y：\nh = fi(z) # φ(Sigma(wi*xi) + b) ReLU 函數: f(x) = max(0, x) # 目前最流行 Sigmoid 函數: f(x) = 1 / (1 + exp(-x)) # 最接近人類神經元的函數 Tanh 函數: f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x)) # 雙曲正切函數 Gaussian 函數: f(x) = exp(-x^2) # 高斯函數，已經是舊時代的產物了 要學習的參數 theta = {wi, b}\n開始打造神經網路，函數學習機 Example: 2 個輸入 x1, x2，1 個輸出 y1 的模型，以全連結神經網路為例，製作一個函數學習機。\nDNN 一層只需要決定有幾個神經元，例如準備 3 個神經元（三個蘿蔔坑），而前一層有 2 個輸入（兩個蘿蔔），分別會一一對應到這三個坑裡，1 -\u003e 1, 1 -\u003e 2, 1 -\u003e 3, 2 -\u003e 1, 2 -\u003e 2, 2 -\u003e 3。再下一層時，隨意指定要幾個神經元後，也會依序對應， 1 -\u003e 1, 1 -\u003e 2, 1 -\u003e 3, 2 -\u003e 1, 2 -\u003e 2, 2 -\u003e 3, 3 -\u003e 1, 3 -\u003e 2, 3 -\u003e 3。\n這就是訓練的過程，過程中會決定每個神經元的權重 w1, w2, …, wn 和偏值 b，合併起來就是模型的參數 theta θ。 { w1, w2, …, wn, b1, b2, …, bm }\nLoss function 損失函數 損失函數是用來衡量模型預測結果與真實結果之間差異的函數。常見的損失函數有均方誤差（Mean Squared Error, MSE）和交叉熵損失（Cross-Entropy Loss）。\n就是 Mean Squared Error (MSE) 啦！突然就回到機率課的回憶了（死去的記憶正在攻擊我），之前沒什麼方向在學，所以沒學好那門課。\n$$L(\\theta) = \\frac{1}{2k} \\sum_{i=1}^k ||y_i - f_\\theta(\\mathbf{x}_i)||^2$$\n其中：\n$\\theta$ 表示模型參數 $k$ 是樣本數量 $y_i$ 是真實值 $f_\\theta(\\mathbf{x}_i)$ 是模型預測值 $||.||^2$ 表示歐幾里得距離的平方 所謂訓練，就是想辦法讓 loss 越來越小。 L(θ1) \u003e L(θ2) \u003e L(θ3) \u003e … \u003e L(θn)，也就是梯度下降法 (Gradient Descent)的過程。\n參數調整 假裝現在只有一個 w 參數，對於參數 w 來說，調整的方向是讓損失函數 L 變小，也就是讓 L 對 w 的偏微分（partial derivative）變小。\n-η * (∂L / ∂w)\nη 是學習率（learning rate），決定每次調整的幅度。 ∂L / ∂w 是損失函數對參數 w 的偏微分，表示損失函數對 w 的變化率。 這個過程會重複進行，直到損失函數 L 收斂到一個較小的值，或者達到預定的迭代次數為止。 如果遇到斜率產生逆變化，代表可能已經到達局部極小值，這時候就要調整學習率 η，讓它變小一點，避免跳過極小值。這有點像我們在求一個圖形的最低點時，人眼可以很明顯地看到最低點在哪裡，但電腦計算得透過微分來判斷斜率的變化與比較，來得知最低點的位置。 在 w=a 點的切線斜率符號長這樣：\nL'(a) 對任意點 w 來說，我們寫成函數形式長這樣：\nL'(w) = ∂L / ∂w 在 w=a 中，我們可以調整成新的 w 值：\na - L\\'(a) 對任意 w 來說，使用這樣的公式來調整 w 值：\nw - dL/dw 偏微分 ∂L / ∂w 是偏微分的符號，表示損失函數 L 對參數 w 的偏微分。\n偏微分是指在多變數函數中，對其中一個變數求導數，其他變數保持不變。\n∂L / ∂w = dL_w1 / dw_1，意思是把 w1 調整成 w1 - η * (∂L / ∂w1)\n[w1, w2, w3, …, wn] \u003c- [w1, w2, w3, …, wn] - η * [∂L/∂w1, ∂L/∂w2, ∂L/∂w3, …, ∂L/∂wn] = Gradient Descent = [w1, w2, w3, …, wn] - η * ∇L （梯度 gradient）\n","wordCount":"579","inLanguage":"en","image":"https://blog.imych.one/images/banner.webp","datePublished":"2025-09-14T22:30:12+08:00","dateModified":"2025-09-14T22:30:12+08:00","author":{"@type":"Person","name":{"name":"油成"}},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.imych.one/2025-fall-taica-generative-ai/"},"publisher":{"@type":"Organization","name":"YC Photography","logo":{"@type":"ImageObject","url":"https://imych.one/assets/youu.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.imych.one/ accesskey=h title="YC Photography (Alt + H)">YC Photography</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.imych.one/tags/now/ title=Now><span>Now</span></a></li><li><a href=https://blog.imych.one/invitation-code/ title=邀請碼><span>邀請碼</span></a></li><li><a href=https://blog.imych.one/categories/ title=分類><span>分類</span></a></li><li><a href=https://blog.imych.one/tags/ title=標籤><span>標籤</span></a></li><li><a href=https://blog.imych.one/about/ title=關於><span>關於</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">2025 Fall Taica Generative AI 文字與圖像生成的原理與實務 筆記（持續更新中）</h1><div class=post-meta>油成 · 2025 年 09 月 14 日 發布</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e6%8c%87%e4%bb%a4%e5%bd%99%e6%95%b4 aria-label=指令彙整>指令彙整</a><ul><li><a href=#-jupyter-notebook-%e9%ad%94%e8%a1%93%e6%8c%87%e4%bb%a4 aria-label="% Jupyter Notebook 魔術指令">% Jupyter Notebook 魔術指令</a></li><li><a href=#import-%e6%a8%99%e6%ba%96%e5%bc%95%e5%85%a5%e5%a5%97%e4%bb%b6 aria-label="import 標準引入套件">import 標準引入套件</a></li><li><a href=#-%e5%9f%b7%e8%a1%8c%e7%b3%bb%e7%b5%b1%e6%8c%87%e4%bb%a4 aria-label="! 執行系統指令">! 執行系統指令</a></li><li><a href=#plot-example aria-label="plot example">plot example</a></li><li><a href=#%e4%ba%92%e5%8b%95%e6%a8%a1%e5%bc%8f aria-label=互動模式>互動模式</a></li></ul></li><li><a href=#%e7%a5%9e%e7%b6%93%e7%b6%b2%e8%b7%af aria-label=神經網路>神經網路</a><ul><li><a href=#softmax aria-label=softmax>softmax</a></li><li><a href=#%e7%a5%9e%e7%b6%93%e5%85%83 aria-label=神經元>神經元</a><ul><li><a href=#%e8%a8%88%e7%ae%97%e7%b8%bd%e5%88%ba%e6%bf%80 aria-label=計算總刺激>計算總刺激</a></li><li><a href=#%e5%8a%a0%e4%b8%8a%e5%81%8f%e5%80%bc aria-label=加上偏值>加上偏值</a></li><li><a href=#%e6%b4%bb%e5%8c%96%e5%87%bd%e6%95%b8%e6%bf%80%e7%99%bc%e5%87%bd%e6%95%b8%e8%bd%89%e6%8f%9b aria-label=活化函數（激發函數）轉換>活化函數（激發函數）轉換</a></li><li><a href=#%e8%a6%81%e5%ad%b8%e7%bf%92%e7%9a%84%e5%8f%83%e6%95%b8 aria-label=要學習的參數>要學習的參數</a></li></ul></li><li><a href=#%e9%96%8b%e5%a7%8b%e6%89%93%e9%80%a0%e7%a5%9e%e7%b6%93%e7%b6%b2%e8%b7%af%e5%87%bd%e6%95%b8%e5%ad%b8%e7%bf%92%e6%a9%9f aria-label=開始打造神經網路，函數學習機>開始打造神經網路，函數學習機</a></li><li><a href=#loss-function-%e6%90%8d%e5%a4%b1%e5%87%bd%e6%95%b8 aria-label="Loss function 損失函數">Loss function 損失函數</a></li><li><a href=#%e5%8f%83%e6%95%b8%e8%aa%bf%e6%95%b4 aria-label=參數調整>參數調整</a></li><li><a href=#%e5%81%8f%e5%be%ae%e5%88%86 aria-label=偏微分>偏微分</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=指令彙整>指令彙整<a hidden class=anchor aria-hidden=true href=#指令彙整>#</a></h1><h2 id=-jupyter-notebook-魔術指令><code>%</code> Jupyter Notebook 魔術指令<a hidden class=anchor aria-hidden=true href=#-jupyter-notebook-魔術指令>#</a></h2><ul><li><code>%matplotlib inline</code> 圖表直接顯示在頁面裡</li><li><code>%save filename.py 1-5</code> 儲存第 1 到 5 行程式碼到 filename.py</li><li><code>%run filename.py</code> 執行 filename.py</li><li><code>%timeit code</code> 測量 code 執行時間</li></ul><h2 id=import-標準引入套件><code>import</code> 標準引入套件<a hidden class=anchor aria-hidden=true href=#import-標準引入套件>#</a></h2><ul><li>import numpy as np</li><li>import pandas as pd</li><li>import matplotlib.pyplot as plt</li></ul><h2 id=-執行系統指令><code>!</code> 執行系統指令<a hidden class=anchor aria-hidden=true href=#-執行系統指令>#</a></h2><ul><li><code>!ls</code> 列出目錄內容</li><li><code>!pip install package</code> 安裝 Python 套件</li><li><code>!pwd</code> 顯示目前工作目錄</li></ul><h2 id=plot-example>plot example<a hidden class=anchor aria-hidden=true href=#plot-example>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 從標準常態分佈隨機抽樣</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>randn(<span style=color:#ae81ff>100</span>)) <span style=color:#75715e># 由標準常態分布隨機取 100 個數。</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 畫圖王牌指令: plt.plot</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot([<span style=color:#ae81ff>3</span>,<span style=color:#f92672>-</span><span style=color:#ae81ff>5</span>,<span style=color:#ae81ff>7</span>,<span style=color:#ae81ff>2</span>]) <span style=color:#75715e># 畫出 (0,3), (1, -5), (2,7),  (3,2) 四個點並連線</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(x, y) <span style=color:#75715e># 點的 x 座標 list, y 座標 list</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot([<span style=color:#ae81ff>0.8</span>, <span style=color:#ae81ff>1.2</span>, <span style=color:#ae81ff>2.1</span>, <span style=color:#ae81ff>2.8</span>], [<span style=color:#ae81ff>2</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>3.2</span>, <span style=color:#ae81ff>5</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 點的表示法</span>
</span></span><span style=display:flex><span>points <span style=color:#f92672>=</span> [(<span style=color:#ae81ff>0.8</span>, <span style=color:#ae81ff>2</span>), (<span style=color:#ae81ff>1.2</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>5</span>), (<span style=color:#ae81ff>2.1</span>, <span style=color:#ae81ff>3.2</span>), (<span style=color:#ae81ff>2.8</span>, <span style=color:#ae81ff>5</span>)]
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> [<span style=color:#ae81ff>0.8</span>, <span style=color:#ae81ff>1.2</span>, <span style=color:#ae81ff>2.1</span>, <span style=color:#ae81ff>2.8</span>]
</span></span><span style=display:flex><span>y <span style=color:#f92672>=</span> [<span style=color:#ae81ff>2</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>3.2</span>, <span style=color:#ae81ff>5</span>]
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(x, y, <span style=color:#e6db74>&#39;o&#39;</span>) <span style=color:#75715e># 用圓圈表示點</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(x, y, <span style=color:#e6db74>&#39;ro&#39;</span>) <span style=color:#75715e># 用紅色圓圈表示點</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(x, y, <span style=color:#e6db74>&#39;g^&#39;</span>) <span style=color:#75715e># 用綠色三角形表示</span>
</span></span></code></pre></div><h2 id=互動模式>互動模式<a hidden class=anchor aria-hidden=true href=#互動模式>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> ipywidgets <span style=color:#f92672>import</span> interact <span style=color:#75715e># 讀入 interact 函式，進入互動模式</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>move</span>(x<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>  print(<span style=color:#e6db74>&#34; &#34;</span><span style=color:#f92672>*</span>x <span style=color:#f92672>+</span> <span style=color:#e6db74>&#34;oooo&#34;</span>)
</span></span><span style=display:flex><span>interact(move, n<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>50</span>))
</span></span></code></pre></div><p>視覺畫圖表</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>x <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linspace(<span style=color:#f92672>-</span><span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>1000</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>draw</span>(n<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>    y <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sinc(n<span style=color:#f92672>*</span>x)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>plot(x,y, lw<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>)
</span></span></code></pre></div><h1 id=神經網路>神經網路<a hidden class=anchor aria-hidden=true href=#神經網路>#</a></h1><h2 id=softmax>softmax<a hidden class=anchor aria-hidden=true href=#softmax>#</a></h2><p>目標是把任意的 a, b, c 三個數字, 轉化為 p1, p2, p3, 而且保持大小關係不變，而且所有數字加起來等於 1。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>p1 <span style=color:#f92672>+</span> p2 <span style=color:#f92672>+</span> p3 <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span></code></pre></div><p>接著，很自然地會想到用指數函數來做轉換，因為指數函數是單調遞增的函數。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>Let S <span style=color:#f92672>=</span> e<span style=color:#f92672>^</span>a <span style=color:#f92672>+</span> e<span style=color:#f92672>^</span>b <span style=color:#f92672>+</span> e<span style=color:#f92672>^</span>c
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Then we can define:
</span></span><span style=display:flex><span>a b c <span style=color:#f92672>-&gt;</span> e<span style=color:#f92672>^</span>a e<span style=color:#f92672>^</span>b e<span style=color:#f92672>^</span>c <span style=color:#f92672>-&gt;</span> e<span style=color:#f92672>^</span>a<span style=color:#f92672>/</span>S e<span style=color:#f92672>^</span>b<span style=color:#f92672>/</span>S e<span style=color:#f92672>^</span>c<span style=color:#f92672>/</span>S
</span></span><span style=display:flex><span>每個數字經過指數函數轉換<span style=color:#960050;background-color:#1e0010>，</span>再來按比例計算<span style=color:#960050;background-color:#1e0010>，</span>這就是 softmax 的定義<span style=color:#960050;background-color:#1e0010>。</span>
</span></span></code></pre></div><h2 id=神經元>神經元<a hidden class=anchor aria-hidden=true href=#神經元>#</a></h2><p>「神經元」是「神經網路」的基本運算單位，建立一個個隱藏層（hidden layer），每個隱藏層包含多個神經元。每個神經元會接收來自前一層的輸入，進行加權和（weighted sum）運算，然後藉由一個非線性活化函數（或稱作激發函數）（activation function）來產生輸出。</p><ul><li>DNN: Deep Neural Network 深度神經網路 標準全連結，全面考慮型</li><li>CNN: Convolutional Neural Network 卷積神經網路 圖形辨識能力很強</li><li>RNN: Recurrent Neural Network 循環神經網路 適合處理序列資料 有記憶的結構</li><li>Transformer: 變壓器架構 目前最流行的架構</li></ul><blockquote><p>流程：計算總刺激 -> 加上偏值 -> 活化函數轉換</p></blockquote><h3 id=計算總刺激>計算總刺激<a hidden class=anchor aria-hidden=true href=#計算總刺激>#</a></h3><p>這很像是線性迴歸的計算方式，假設有 n 個輸入 x1, x2, &mldr;, xn，對應的權重為 w1, w2, &mldr;, wn，則總刺激 z 的計算公式如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>z <span style=color:#f92672>=</span> w1<span style=color:#f92672>*</span>x1 <span style=color:#f92672>+</span> w2<span style=color:#f92672>*</span>x2 <span style=color:#f92672>+</span> <span style=color:#f92672>...</span> <span style=color:#f92672>+</span> wn<span style=color:#f92672>*</span>xn
</span></span></code></pre></div><h3 id=加上偏值>加上偏值<a hidden class=anchor aria-hidden=true href=#加上偏值>#</a></h3><p>在計算總刺激後，會加上一個偏值（bias） b，這個偏值可以幫助模型更靈活地調整輸出。加上偏值後的公式變為：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>z <span style=color:#f92672>=</span> (sigma(wi<span style=color:#f92672>*</span>xi) <span style=color:#f92672>from</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> to n) <span style=color:#f92672>+</span> b
</span></span></code></pre></div><h3 id=活化函數激發函數轉換>活化函數（激發函數）轉換<a hidden class=anchor aria-hidden=true href=#活化函數激發函數轉換>#</a></h3><p>最後，將總刺激 z 放入一個非線性活化函數 fi φ 來產生神經元的輸出 y：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>h <span style=color:#f92672>=</span> fi(z) <span style=color:#75715e># φ(Sigma(wi*xi) + b)</span>
</span></span></code></pre></div><ul><li>ReLU 函數: f(x) = max(0, x) # 目前最流行</li><li>Sigmoid 函數: f(x) = 1 / (1 + exp(-x)) # 最接近人類神經元的函數</li><li>Tanh 函數: f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x)) # 雙曲正切函數</li><li>Gaussian 函數: f(x) = exp(-x^2) # 高斯函數，已經是舊時代的產物了</li></ul><h3 id=要學習的參數>要學習的參數<a hidden class=anchor aria-hidden=true href=#要學習的參數>#</a></h3><p>theta = {wi, b}</p><h2 id=開始打造神經網路函數學習機>開始打造神經網路，函數學習機<a hidden class=anchor aria-hidden=true href=#開始打造神經網路函數學習機>#</a></h2><p>Example: 2 個輸入 x1, x2，1 個輸出 y1 的模型，以全連結神經網路為例，製作一個函數學習機。</p><p>DNN 一層只需要決定有幾個神經元，例如準備 3 個神經元（三個蘿蔔坑），而前一層有 2 個輸入（兩個蘿蔔），分別會一一對應到這三個坑裡，1 -> 1, 1 -> 2, 1 -> 3, 2 -> 1, 2 -> 2, 2 -> 3。再下一層時，隨意指定要幾個神經元後，也會依序對應， 1 -> 1, 1 -> 2, 1 -> 3, 2 -> 1, 2 -> 2, 2 -> 3, 3 -> 1, 3 -> 2, 3 -> 3。</p><p>這就是訓練的過程，過程中會決定每個神經元的權重 w1, w2, &mldr;, wn 和偏值 b，合併起來就是模型的參數 theta θ。
{ w1, w2, &mldr;, wn, b1, b2, &mldr;, bm }</p><h2 id=loss-function-損失函數>Loss function 損失函數<a hidden class=anchor aria-hidden=true href=#loss-function-損失函數>#</a></h2><p>損失函數是用來衡量模型預測結果與真實結果之間差異的函數。常見的損失函數有均方誤差（Mean Squared Error, MSE）和交叉熵損失（Cross-Entropy Loss）。</p><p>就是 <strong>Mean Squared Error (MSE)</strong> 啦！突然就回到機率課的回憶了（死去的記憶正在攻擊我），之前沒什麼方向在學，所以沒學好那門課。</p><p>$$L(\theta) = \frac{1}{2k} \sum_{i=1}^k ||y_i - f_\theta(\mathbf{x}_i)||^2$$</p><p>其中：</p><ul><li>$\theta$ 表示模型參數</li><li>$k$ 是樣本數量</li><li>$y_i$ 是真實值</li><li>$f_\theta(\mathbf{x}_i)$ 是模型預測值</li><li>$||.||^2$ 表示歐幾里得距離的平方</li></ul><p>所謂訓練，就是想辦法讓 loss 越來越小。 L(θ1) > L(θ2) > L(θ3) > &mldr; > L(θn)，也就是梯度下降法 (Gradient Descent)的過程。</p><h2 id=參數調整>參數調整<a hidden class=anchor aria-hidden=true href=#參數調整>#</a></h2><p>假裝現在只有一個 w 參數，對於參數 w 來說，調整的方向是讓損失函數 L 變小，也就是讓 L 對 w 的偏微分（partial derivative）變小。</p><p>-η * (∂L / ∂w)</p><ul><li>η 是學習率（learning rate），決定每次調整的幅度。</li><li>∂L / ∂w 是損失函數對參數 w 的偏微分，表示損失函數對 w 的變化率。
這個過程會重複進行，直到損失函數 L 收斂到一個較小的值，或者達到預定的迭代次數為止。
如果遇到斜率產生逆變化，代表可能已經到達局部極小值，這時候就要調整學習率 η，讓它變小一點，避免跳過極小值。這有點像我們在求一個圖形的最低點時，人眼可以很明顯地看到最低點在哪裡，但電腦計算得透過微分來判斷斜率的變化與比較，來得知最低點的位置。</li></ul><p>在 w=a 點的切線斜率符號長這樣：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>L<span style=color:#e6db74>&#39;(a)</span>
</span></span></code></pre></div><p>對任意點 w 來說，我們寫成函數形式長這樣：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>L<span style=color:#e6db74>&#39;(w) = ∂L / ∂w</span>
</span></span></code></pre></div><p>在 w=a 中，我們可以調整成新的 w 值：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>a <span style=color:#f92672>-</span> L\<span style=color:#e6db74>&#39;(a)</span>
</span></span></code></pre></div><p>對任意 w 來說，使用這樣的公式來調整 w 值：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>w <span style=color:#f92672>-</span> dL<span style=color:#f92672>/</span>dw
</span></span></code></pre></div><h2 id=偏微分>偏微分<a hidden class=anchor aria-hidden=true href=#偏微分>#</a></h2><p>∂L / ∂w 是偏微分的符號，表示損失函數 L 對參數 w 的偏微分。</p><blockquote><p>偏微分是指在多變數函數中，對其中一個變數求導數，其他變數保持不變。</p></blockquote><p>∂L / ∂w = dL_w1 / dw_1，意思是把 w1 調整成 w1 - η * (∂L / ∂w1)</p><p>[w1, w2, w3, &mldr;, wn] &lt;- [w1, w2, w3, &mldr;, wn] - η * [∂L/∂w1, ∂L/∂w2, ∂L/∂w3, &mldr;, ∂L/∂wn]
= Gradient Descent = [w1, w2, w3, &mldr;, wn] - η * ∇L （梯度 gradient）</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.imych.one/tags/%E4%BF%AE%E8%AA%B2%E7%B4%80%E9%8C%84/>修課紀錄</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.imych.one/>YC Photography</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>